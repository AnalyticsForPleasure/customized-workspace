<templateSet group="Keras">
  <template name="gc-keras-augmentation" value="    num_classes = $NUM_CLASSES$&#10;    img_rows, img_cols = $SHAPE$&#10;    batch_size = $BATCH_SIZE$&#10;&#10;    train_data_dir = $PATH_TO_TRAIN$&#10;    validation_data_dir = './fruits-360/validation'&#10;&#10;    ## Without data augmentation, just write:&#10;    # ImageDataGenerator(rescale=1. / 255)&#10;    &#10;    # Let's use some data augmentation&#10;    &#10;    train_datagen = ImageDataGenerator(rescale=1. / 255,&#10;                                       rotation_range=30, # The image will rotate by an angle between 0 to 30 degrees&#10;                                       width_shift_range=0.3, # Randomally shift the image by most 20 percent horizontally&#10;                                       height_shift_range=0.3, # Randomally shift the image by 20 most percent vertically&#10;                                       shear_range = 0.2,&#10;                                       zoom_range = 0.2,&#10;                                       horizontal_flip=True, # Mirroring at random&#10;                                       fill_mode = 'nearest' # For the pixels that have might been lost by those augemtaion's operations&#10;                                       )&#10;&#10;    validation_datagen = ImageDataGenerator(rescale=1. / 255)&#10;&#10;    train_generator = train_datagen.flow_from_directory(&#10;        train_data_dir,&#10;        target_size=(img_rows, img_cols),&#10;        batch_size=batch_size,&#10;        class_mode='categorical', # OR 'binary'&#10;        shuffle=True&#10;    )&#10;&#10;    validation_generator = validation_datagen.flow_from_directory(&#10;        validation_data_dir,&#10;        target_size=(img_rows, img_cols),&#10;        batch_size=batch_size,&#10;        class_mode='categorical', # OR 'binary'&#10;        shuffle=True&#10;    )&#10;    &#10;    history = model.fit(train_generator,&#10;                              epochs=15,&#10;                              verbose=1,&#10;                              validation_data=validation_generator)" description="" toReformat="false" toShortenFQNames="true">
    <variable name="NUM_CLASSES" expression="" defaultValue="&quot;81&quot;" alwaysStopAt="true" />
    <variable name="SHAPE" expression="" defaultValue="&quot;32, 32&quot;" alwaysStopAt="true" />
    <variable name="BATCH_SIZE" expression="" defaultValue="&quot;16&quot;" alwaysStopAt="true" />
    <variable name="PATH_TO_TRAIN" expression="" defaultValue="&quot;'./fruits-360/train'&quot;" alwaysStopAt="true" />
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
  <template name="gc-keras-bring-up-model" value="from keras.models import Sequential&#10;from keras.layers import Dense, Dropout, Flatten&#10;from keras.layers import Conv2D, MaxPooling2D&#10;&#10;&#10;input_shape = (img_rows, img_cols, 3)  # 3 since it's RGB&#10;&#10;model = Sequential()&#10;model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=input_shape))&#10;model.add(Activation('relu'))&#10;model.add(MaxPooling2D(pool_size=(2, 2)))&#10;&#10;model.add(Conv2D(filters=32, kernel_size=(3, 3)))&#10;model.add(Activation('relu'))&#10;model.add(MaxPooling2D(pool_size=(2, 2)))&#10;&#10;model.add(Conv2D(filters=64, kernel_size=(3, 3)))&#10;model.add(Activation('relu'))&#10;model.add(MaxPooling2D(pool_size=(2, 2)))&#10;&#10;model.add(Flatten())&#10;model.add(Dense(64))&#10;model.add(Activation('relu'))&#10;model.add(Dropout(0.5))&#10;model.add(Dense(1))&#10;model.add(Activation('sigmoid'))&#10;&#10;# We have two classes therefore we have used: binary_crossentropy&#10;# Categorical_crossentropy was for multiple classifier.&#10;model.compile(loss='binary_crossentropy',&#10;              optimizer='rmsprop',&#10;              metrics=['accuracy'])&#10;&#10;print(model.summary())&#10;return model&#10;" description="" toReformat="false" toShortenFQNames="true">
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
  <template name="gc-keras-callbacks" value="from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau&#10;&#10;    checkpoint = ModelCheckpoint(&quot;./trained_models/fruits_fresh_cnn_1.h5&quot;,&#10;                                 monitor=&quot;val_loss&quot;,&#10;                                 mode=&quot;min&quot;,&#10;                                 save_best_only=True,&#10;                                 verbose=1)&#10;&#10;    early_stop = EarlyStopping(monitor='val_loss',&#10;                               min_delta=0,&#10;                               patience=3,&#10;                               verbose=1,&#10;                               restore_best_weights=True)&#10;&#10;    reduce_lr = ReduceLROnPlateau(monitor='val_loss',&#10;                                  factor=0.2,&#10;                                  patience=3,&#10;                                  verbose=1,&#10;                                  min_delta=0.0001)&#10;&#10;    # we put our callbacks into a callback list&#10;    callbacks = [early_stop, checkpoint, reduce_lr]&#10;&#10;    model.compile(loss='categorical_crossentropy',&#10;                  optimizer=RMSprop(lr=0.001),&#10;                  metrics=['accuracy'])&#10;&#10;    n_train_samples = 41322&#10;    n_validation_samples = 13877&#10;    epochs = 5&#10;&#10;    history = model.fit_generator(&#10;        train_generator,&#10;        steps_per_epoch=n_train_samples // batch_size,&#10;        epochs=epochs,&#10;        callbacks=callbacks,&#10;        validation_data=validation_generator,&#10;        validation_steps=n_validation_samples // batch_size&#10;    )" description="" toReformat="false" toShortenFQNames="true">
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
  <template name="gc-keras-plot-training-and-validation-metrics" value="import matplotlib.image  as mpimg&#10;import matplotlib.pyplot as plt&#10;&#10;#-----------------------------------------------------------&#10;# Retrieve a list of list results on training and test data&#10;# sets for each training epoch&#10;#-----------------------------------------------------------&#10;acc=history.history['accuracy']&#10;val_acc=history.history['val_accuracy']&#10;loss=history.history['loss']&#10;val_loss=history.history['val_loss']&#10;&#10;epochs=range(len(acc)) # Get number of epochs&#10;&#10;#------------------------------------------------&#10;# Plot training and validation accuracy per epoch&#10;#------------------------------------------------&#10;plt.plot(epochs, acc, 'r', &quot;Training Accuracy&quot;)&#10;plt.plot(epochs, val_acc, 'b', &quot;Validation Accuracy&quot;)&#10;plt.title('Training and validation accuracy')&#10;plt.figure()&#10;&#10;#------------------------------------------------&#10;# Plot training and validation loss per epoch&#10;#------------------------------------------------&#10;plt.plot(epochs, loss, 'r', &quot;Training Loss&quot;)&#10;plt.plot(epochs, val_loss, 'b', &quot;Validation Loss&quot;)&#10;&#10;&#10;plt.title('Training and validation loss')&#10;&#10;# Desired output. Charts with training and validation metrics. No crash :)" description="Charts with training and validation metrics." toReformat="false" toShortenFQNames="true">
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
</templateSet>